{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Approximate-Nearest-Neighbors-with-Locality-sensitive-hashing-\" data-toc-modified-id=\"Approximate-Nearest-Neighbors-with-Locality-sensitive-hashing--1\">Approximate Nearest Neighbors with Locality-sensitive hashing </a></span></li><li><span><a href=\"#Why-would-need-approximate-nearest-neighors-(ANN)-search?\" data-toc-modified-id=\"Why-would-need-approximate-nearest-neighors-(ANN)-search?-2\">Why would need approximate nearest neighors (ANN) search?</a></span></li><li><span><a href=\"#Locality-sensitive-hashing-(LSH)\" data-toc-modified-id=\"Locality-sensitive-hashing-(LSH)-3\">Locality-sensitive hashing (LSH)</a></span></li><li><span><a href=\"#A-brief-review-of-Jaccard-Distance\" data-toc-modified-id=\"A-brief-review-of-Jaccard-Distance-4\">A brief review of Jaccard Distance</a></span></li><li><span><a href=\"#Worked-example-of-Jaccard-Distance-with-boolean-values\" data-toc-modified-id=\"Worked-example-of-Jaccard-Distance-with-boolean-values-5\">Worked example of Jaccard Distance with boolean values</a></span></li><li><span><a href=\"#Locality-Sensitive-Hashing-(LSH)-extend-Jaccard-Distance\" data-toc-modified-id=\"Locality-Sensitive-Hashing-(LSH)-extend-Jaccard-Distance-6\">Locality-Sensitive Hashing (LSH) extend Jaccard Distance</a></span></li><li><span><a href=\"#How-would-you-find-exact-matches-for-documents-/-strings?\" data-toc-modified-id=\"How-would-you-find-exact-matches-for-documents-/-strings?-7\">How would you find exact matches for documents / strings?</a></span></li><li><span><a href=\"#Steps-to-apply-LSH-to-find-near-duplicates-documents\" data-toc-modified-id=\"Steps-to-apply-LSH-to-find-near-duplicates-documents-8\">Steps to apply LSH to find near-duplicates documents</a></span></li><li><span><a href=\"#Min-hashing-for-making-shingles-(if-you-don't-have-doc2vec)\" data-toc-modified-id=\"Min-hashing-for-making-shingles-(if-you-don't-have-doc2vec)-9\">Min-hashing for making shingles (if you don't have doc2vec)</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-10\">Check for understanding</a></span></li><li><span><a href=\"#LSH-hashing-in-N-dimensions\" data-toc-modified-id=\"LSH-hashing-in-N-dimensions-11\">LSH hashing in N dimensions</a></span></li><li><span><a href=\"#More-realists-example-of-LSH\" data-toc-modified-id=\"More-realists-example-of-LSH-12\">More realists example of LSH</a></span></li><li><span><a href=\"#Primarily-advantages-of-LSH\" data-toc-modified-id=\"Primarily-advantages-of-LSH-13\">Primarily advantages of LSH</a></span></li><li><span><a href=\"#LSH-can-overcome-the-Curse-of-Dimensionality\" data-toc-modified-id=\"LSH-can-overcome-the-Curse-of-Dimensionality-14\">LSH can overcome the Curse of Dimensionality</a></span></li><li><span><a href=\"#LSH-works-with-noisy-data\" data-toc-modified-id=\"LSH-works-with-noisy-data-15\">LSH works with noisy data</a></span></li><li><span><a href=\"#What-are-some-general-applications-of-LSH?\" data-toc-modified-id=\"What-are-some-general-applications-of-LSH?-16\">What are some general applications of LSH?</a></span></li><li><span><a href=\"#How-do-companies-use-LSH?\" data-toc-modified-id=\"How-do-companies-use-LSH?-17\">How do companies use LSH?</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-18\">Check for understanding</a></span></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-19\">Takeaways</a></span></li><li><span><a href=\"#Bonus-Materials\" data-toc-modified-id=\"Bonus-Materials-20\">Bonus Materials</a></span></li><li><span><a href=\"#Python-Implement?-Hell-Yeah!\" data-toc-modified-id=\"Python-Implement?-Hell-Yeah!-21\">Python Implement? Hell Yeah!</a></span></li><li><span><a href=\"#LSH-Pro-Tips\" data-toc-modified-id=\"LSH-Pro-Tips-22\">LSH Pro Tips</a></span></li><li><span><a href=\"#Additional-Resources\" data-toc-modified-id=\"Additional-Resources-23\">Additional Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Approximate Nearest Neighbors with Locality-sensitive Hashing </h2></center>\n",
    "\n",
    "<center><img src=\"images/voronoi_region.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Why would need approximate nearest neighors (ANN) search?</h2></center>\n",
    "<br>\n",
    "\n",
    "If you worked an employment website and wanted to match people to jobs:\n",
    "\n",
    "<center><img src=\"images/matching.png\" width=\"35%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__What general type of algorithm problem is this?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bipartite graph matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Approximately, how does scale? How many more possible edges/connections are there for each new node?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "O(n<sup>2</sup>) or O(nm) \n",
    "\n",
    "Each new node has to be compared to all possible existing on the other side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__What is the best algorithm to solve this type of matching problem?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is called a \"stable marriage problem\" and is best solved with __Gale Shapley Algorithm__\n",
    "\n",
    "It involves a number of \"rounds\" (or \"iterations\"). In the first round, first a) each unengaged man proposes to the woman he prefers most, and then b) each woman replies \"maybe\" to her suitor she most prefers and \"no\" to all other suitors. She is then provisionally \"engaged\" to the suitor she most prefers so far, and that suitor is likewise provisionally engaged to her. \n",
    "\n",
    "In each subsequent round, first a) each unengaged man proposes to the most-preferred woman to whom he has not yet proposed (regardless of whether the woman is already engaged), and then b) each woman replies \"maybe\" if she is currently not engaged or if she prefers this guy over her current provisional partner (in this case, she rejects her current provisional partner who becomes unengaged). \n",
    "\n",
    "The provisional nature of engagements preserves the right of an already-engaged woman to \"trade up\" (and, in the process, to \"jilt\" her until-then partner). \n",
    "\n",
    "This process is repeated until everyone is engaged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__How would this process scale for with millions of jobs and job seekers?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Locality-sensitive hashing (LSH)</h2></center>\n",
    "\n",
    "<center><img src=\"images/lsh_overview.png\" width=\"35%\"/></center>\n",
    "\n",
    "- Locality-sensitive hashing (LSH) does approximate set similarity.\n",
    "- Hashes to cluster similar items. \"Similar\" items are likely to be hashed to the same bucket (with high probability).\n",
    "- Avoids all-pairs comparison (aka, cartesian-product hell).\n",
    "- One useful approach for Approximate Nearest Neighbor (ANN) search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>A brief review of Jaccard Distance</h2></center>\n",
    "\n",
    "Jaccard Distance measures set similarity.\n",
    "\n",
    "<center><img src=\"images/jaccard.png\" width=\"35%\"/></center>\n",
    "\n",
    "<center><img src=\"images/jaccard_formula.png\" width=\"35%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Worked example of Jaccard Distance with boolean values</h2></center>\n",
    "\n",
    "- We can encode sets using 0 or 1 (bit/boolean) vectors\n",
    "- One dimension per element\n",
    "- Interpretation:\n",
    "    - Set intersection as bitwise AND \n",
    "    - Set union as bitwise OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BitVector in /Users/brian/anaconda3/lib/python3.8/site-packages (3.4.9)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install a BitVector pip package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "! {sys.executable} -m pip install BitVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](http://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from BitVector import BitVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  101001\n",
      "b =  100001\n"
     ]
    }
   ],
   "source": [
    "a =  BitVector(bitlist=[1, 0, 1, 0, 0, 1]) \n",
    "print('a = ', a)\n",
    "\n",
    "b =  BitVector(bitlist=[1, 0, 0, 0, 0, 1]) \n",
    "print('b = ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101001'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the union?\n",
    "str(a | b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100001'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is ths intersection?\n",
    "str(a & b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the Jaccard Index?\n",
    "(a & b).count_bits() / (a | b).count_bits() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Locality-Sensitive Hashing (LSH) extend Jaccard Distance</h2></center>\n",
    "\n",
    "\n",
    "LSH finds approximate near-neighbors by dividing the space into regions and looking at the overlap in the regions (aka, Jaccard distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How would you find exact matches for documents / strings?</h2></center>\n",
    "\n",
    "A hash map!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Steps to apply LSH to find near-duplicates documents</h2></center>\n",
    "\n",
    "- Embed documents into a vector space (use a \"shingle\" or doc2vec)\n",
    "- Then hash documents into buckets and expect that “most” similar documents would hash into the same bucket\n",
    "- Compare pairs of docs in each bucket to see if they are really near-duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Min-hashing for making shingles (if you don't have doc2vec)</h2></center>\n",
    "\n",
    "<center><img src=\"images/minhash-small.jpg\" width=\"75%\"/></center>\n",
    "\n",
    "- Clearly, the hash function depends on the similarity metric\n",
    "- Not all similarity metrics have a suitable hash function\n",
    "- Fortunately, there is a suitable hash function for Jaccard similarity __Min-hashing__*\n",
    "\n",
    "*: This is very \"hand wavy\". You should check out [Min-hashing on your own](https://www.cs.utah.edu/~jeffp/teaching/cs5955/L5-Minhash.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "How does LSH compare to standard hashing with regard to collisions?\n",
    "\n",
    "It is the opposite:\n",
    "- In standard hashing you do not want collisions\n",
    "- LSH you want collisions. In LSH, collisions are type of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/Locality+Sensitive+Hashing+(LSH).jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>LSH hashing in N dimensions</h2></center>\n",
    "<br>\n",
    "<br>\n",
    "<center><img src=\"images/lsh2_mod_4.jpg\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- Lines are drawn. One side is code as 0 and the the other is 1.\n",
    "- This encodes regions as a bit vector.\n",
    "- The more booleans values in the bit vector two regions share, the closer the regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>More realists example of LSH</h2></center>\n",
    "\n",
    "<center><img src=\"images/lsh_overview.png\" width=\"35%\"/></center>\n",
    "\n",
    "<center><img src=\"images/lsh.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Primarily advantages of LSH</h2></center>\n",
    "\n",
    "- Overcomes the Curse of Dimensionality for neighbor search.\n",
    "- Handles noisy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>LSH can overcome the Curse of Dimensionality</h2></center>\n",
    "\n",
    "<center><img src=\"images/curse.png\" width=\"700\"/></center>\n",
    "\n",
    "- Let’s take a data set with a fixed number N of points. <br>\n",
    "- As we increase the number of dimensions in which these points are embedded, the average distance between points keeps increasing. <br>\n",
    "- Fewer “neighbors” on average within a certain radius of any given point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](http://web.stanford.edu/class/cs345a/slides/04-highdim.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>LSH works with noisy data</h2></center>\n",
    "\n",
    "Since LSH is approximate technique it is robust to noise.\n",
    "\n",
    "Remember to our example of matching job seekers, a resume is not a perfect representation of a person and job posting is not a perfect representation of a company.\n",
    "\n",
    "So finding \"approximate\" neighbors is better. It can find opportunities that might not be \"perfect\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What are some general applications of LSH?</h2></center>\n",
    "\n",
    "- Given a large number  of items documents, find pairs that are “near duplicates”\n",
    "    - (N in the millions or even billions)\n",
    "    - The items could be documents, images, songs, or videos.\n",
    "- Mirror websites, or approximate mirrors. Don’t want to show both in a search.\n",
    "- Plagiarism, including large quotations.\n",
    "- Similar news articles at many news sites. Cluster articles by “same story”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How do companies use LSH?</h2></center>\n",
    "\n",
    "<center><img src=\"https://i.pinimg.com/originals/76/7c/e3/767ce3287ebeeb4b0215c69ea5ea378b.jpg\" width=\"300\"/></center>\n",
    "\n",
    "YouTube has used for video ad serving. LSH is approximate, fast, and scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/images.png\" width=\"700\"/></center>\n",
    "\n",
    "Airbnb uses it recommend similar properties based on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "How does LSH compare to support vector machines (SVM)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Both LSH and SVM define features space into regions.\n",
    "\n",
    "SVM is use supervised learning technique, thus requires labels.\n",
    "\n",
    "LSH does not learn and does not require labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Locality-sensitive hashing (LSH) takes elements in an feature space and finds nearest neighbors.\n",
    "- Use \"shingling\" or doc2vec to create the space.\n",
    "- Apply the \"pick-up-sticks\" method to divide regions.\n",
    "- Use bit-wise vector operations to find elements in a region / bucket.\n",
    "- LSH is very fast but can make many errors (primarily false positives).\n",
    "- The real world is noisy so this is not a problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Materials\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python Implement? Hell Yeah!\n",
    "-----\n",
    "\n",
    "https://github.com/kayzh/LSHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "LSH Pro Tips\n",
    "---\n",
    "\n",
    "- EMBED ALL THE THINGS! Put metadata and user features into the vector space along with the primary data\n",
    "- Hash items to overlapping buckets to make sure you don't miss near-matches. Create different sets of buckets (it is cheap and fast to hash)\n",
    "- Use all kinds of hashes\n",
    "<img src=\"images/Spherical_Hashing_Figure.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Additional Resources\n",
    "----\n",
    "\n",
    "- [LSH in Spark](https://github.com/mrsqueeze/spark-hash)\n",
    "- [Use LSH to rank in high dimensional spaces](https://www.youtube.com/watch?v=8NNW2kta8og)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
